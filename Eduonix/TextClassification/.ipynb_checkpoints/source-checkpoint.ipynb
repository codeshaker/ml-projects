{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data of sms messages\n",
    "df = pd.read_table('SMSSpamCollection', header = None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Print useful informations about the data set\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 1 1]\n",
      "0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "5    spam\n",
      "6     ham\n",
      "7     ham\n",
      "8    spam\n",
      "9    spam\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convert the class labels to binary values, 0 = ham, 1 = spam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "print(Y[:10])\n",
    "print(classes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Go until jurong point, crazy.. Available only ...\n",
      "1                        Ok lar... Joking wif u oni...\n",
      "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    U dun say so early hor... U c already then say...\n",
      "4    Nah I don't think he goes to usf, he lives aro...\n",
      "5    FreeMsg Hey there darling it's been 3 week's n...\n",
      "6    Even my brother is not like to speak with me. ...\n",
      "7    As per your request 'Melle Melle (Oru Minnamin...\n",
      "8    WINNER!! As a valued network customer you have...\n",
      "9    Had your mobile 11 months or more? U R entitle...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store the sms message data\n",
    "text_messages = df[1]\n",
    "print(text_messages[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regular exp to replace email address, url, phone no, other number, symbols\n",
    "\n",
    "# Replace email addressess with \"emailaddr\"\n",
    "processed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$','emailaddr')\n",
    "\n",
    "# Replace web address with \"webaddress\"\n",
    "processed = text_messages.str.replace(r'#\\b(([\\w-]+://?|www[.])[^\\s()<>]+(?:\\([\\w\\d]+\\)|([^[:punct:]\\s]|/)))#iS$','webaddress')\n",
    "\n",
    "# Replace money symbols with \"moneysymb\"\n",
    "processed = text_messages.str.replace(r'|\\$','moneysymb')\n",
    "\n",
    "# Replace phonenumber with \"phonenumber\"\n",
    "processed = text_messages.str.replace(r'^([\\+][0-9]{1,3}([ \\.\\-])?)?([\\(]{1}[0-9]{3}[\\)])?([0-9A-Z \\.\\-]{1,32})((x|ext|extension)?[0-9]{1,4}?)$','phonenumber')\n",
    "\n",
    "# Replace normal numbers with \"numbr\"\n",
    "processed = text_messages.str.replace(r'\\d+(\\.\\d+)?','numbr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]',' ')\n",
    "\n",
    "# Remove whitespace with single space\n",
    "processed = processed.str.replace(r'\\s+',' ')\n",
    "\n",
    "# Remve leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point crazy available only in ...\n",
      "1                                 ok lar joking wif u oni\n",
      "2       free entry in numbr a wkly comp to win fa cup ...\n",
      "3             u dun say so early hor u c already then say\n",
      "4       nah i don t think he goes to usf he lives arou...\n",
      "                              ...                        \n",
      "5567    this is the numbrnd time we have tried numbr c...\n",
      "5568                  will ü b going to esplanade fr home\n",
      "5569    pity was in mood for that so any other suggest...\n",
      "5570    the guy did some bitching but i acted like i d...\n",
      "5571                            rofl its true to its name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# change the world to lower case - Hello, HELLO, hello are all same\n",
    "processed = processed.str.lower()\n",
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words from text messages\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(term for term in x.split() if term not in stops_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word stems using a Porter Stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazi avail bugi n great world...\n",
      "1                                   ok lar joke wif u oni\n",
      "2       free entri numbr wkli comp win fa cup final tk...\n",
      "3                     u dun say earli hor u c alreadi say\n",
      "4                    nah think goe usf live around though\n",
      "                              ...                        \n",
      "5567    numbrnd time tri numbr contact u u numbr pound...\n",
      "5568                              ü b go esplanad fr home\n",
      "5569                                    piti mood suggest\n",
      "5570    guy bitch act like interest buy someth els nex...\n",
      "5571                                       rofl true name\n",
      "Name: 1, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Creating a bag of words\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of words and 15 most common words\n",
    "print(\"Number of words: {}\".format(len(all_words)))\n",
    "print(\"Most common words: {}\".format(all_words.most_common(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 1500 most common words as features\n",
    "word_features = list(all_words.keys())[:1500]\n",
    "print(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nah think goe usf live around though\n",
      "{'go': 0, 'jurong': 0, 'point': 0, 'crazi': 0, 'avail': 0, 'bugi': 0, 'n': 0, 'great': 0, 'world': 0, 'la': 0, 'e': 0, 'buffet': 0, 'cine': 0, 'got': 0, 'amor': 0, 'wat': 0, 'ok': 0, 'lar': 0, 'joke': 0, 'wif': 0, 'u': 0, 'oni': 0, 'free': 0, 'entri': 0, 'numbr': 0, 'wkli': 0, 'comp': 0, 'win': 0, 'fa': 0, 'cup': 0, 'final': 0, 'tkt': 0, 'numbrst': 0, 'may': 0, 'text': 0, 'receiv': 0, 'question': 0, 'std': 0, 'txt': 0, 'rate': 0, 'c': 0, 'appli': 0, 'numbrovernumbr': 0, 'dun': 0, 'say': 0, 'earli': 0, 'hor': 0, 'alreadi': 0, 'nah': 1, 'think': 1, 'goe': 1, 'usf': 1, 'live': 1, 'around': 1, 'though': 1, 'freemsg': 0, 'hey': 0, 'darl': 0, 'week': 0, 'word': 0, 'back': 0, 'like': 0, 'fun': 0, 'still': 0, 'tb': 0, 'xxx': 0, 'chg': 0, 'send': 0, 'rcv': 0, 'even': 0, 'brother': 0, 'speak': 0, 'treat': 0, 'aid': 0, 'patent': 0, 'per': 0, 'request': 0, 'mell': 0, 'oru': 0, 'minnaminungint': 0, 'nurungu': 0, 'vettam': 0, 'set': 0, 'callertun': 0, 'caller': 0, 'press': 0, 'copi': 0, 'friend': 0, 'winner': 0, 'valu': 0, 'network': 0, 'custom': 0, 'select': 0, 'receivea': 0, 'prize': 0, 'reward': 0, 'claim': 0, 'call': 0, 'code': 0, 'klnumbr': 0, 'valid': 0, 'hour': 0, 'mobil': 0, 'month': 0, 'r': 0, 'entitl': 0, 'updat': 0, 'latest': 0, 'colour': 0, 'camera': 0, 'co': 0, 'gon': 0, 'na': 0, 'home': 0, 'soon': 0, 'want': 0, 'talk': 0, 'stuff': 0, 'anymor': 0, 'tonight': 0, 'k': 0, 'cri': 0, 'enough': 0, 'today': 0, 'six': 0, 'chanc': 0, 'cash': 0, 'pound': 0, 'cshnumbr': 0, 'cost': 0, 'numbrp': 0, 'day': 0, 'numbrday': 0, 'tsandc': 0, 'repli': 0, 'hl': 0, 'info': 0, 'urgent': 0, 'membership': 0, 'jackpot': 0, 'www': 0, 'dbuk': 0, 'net': 0, 'lccltd': 0, 'pobox': 0, 'numbrldnwnumbranumbrrwnumbr': 0, 'search': 0, 'right': 0, 'thank': 0, 'breather': 0, 'promis': 0, 'wont': 0, 'take': 0, 'help': 0, 'grant': 0, 'fulfil': 0, 'wonder': 0, 'bless': 0, 'time': 0, 'date': 0, 'sunday': 0, 'xxxmobilemovieclub': 0, 'use': 0, 'credit': 0, 'click': 0, 'wap': 0, 'link': 0, 'next': 0, 'messag': 0, 'http': 0, 'com': 0, 'qjkgighjjgcbl': 0, 'oh': 0, 'watch': 0, 'eh': 0, 'rememb': 0, 'spell': 0, 'name': 0, 'ye': 0, 'v': 0, 'naughti': 0, 'make': 0, 'wet': 0, 'fine': 0, 'way': 0, 'feel': 0, 'gota': 0, 'b': 0, 'england': 0, 'macedonia': 0, 'dont': 0, 'miss': 0, 'goal': 0, 'team': 0, 'news': 0, 'ur': 0, 'nation': 0, 'eg': 0, 'tri': 0, 'wale': 0, 'scotland': 0, 'numbrtxt': 0, 'únumbr': 0, 'poboxoxnumbrwnumbrwq': 0, 'serious': 0, 'ha': 0, 'ü': 0, 'pay': 0, 'first': 0, 'da': 0, 'stock': 0, 'comin': 0, 'aft': 0, 'finish': 0, 'lunch': 0, 'str': 0, 'lor': 0, 'ard': 0, 'smth': 0, 'ffffffffff': 0, 'alright': 0, 'meet': 0, 'sooner': 0, 'forc': 0, 'eat': 0, 'slice': 0, 'realli': 0, 'hungri': 0, 'tho': 0, 'suck': 0, 'mark': 0, 'get': 0, 'worri': 0, 'know': 0, 'sick': 0, 'turn': 0, 'pizza': 0, 'lol': 0, 'alway': 0, 'convinc': 0, 'catch': 0, 'bu': 0, 'fri': 0, 'egg': 0, 'tea': 0, 'mom': 0, 'left': 0, 'dinner': 0, 'love': 0, 'amp': 0, 'pack': 0, 'car': 0, 'let': 0, 'room': 0, 'ahhh': 0, 'work': 0, 'vagu': 0, 'wait': 0, 'clear': 0, 'sure': 0, 'sarcast': 0, 'x': 0, 'us': 0, 'yeah': 0, 'apologet': 0, 'fallen': 0, 'actin': 0, 'spoilt': 0, 'child': 0, 'caught': 0, 'till': 0, 'badli': 0, 'cheer': 0, 'tell': 0, 'anyth': 0, 'fear': 0, 'faint': 0, 'housework': 0, 'quick': 0, 'cuppa': 0, 'subscript': 0, 'rington': 0, 'uk': 0, 'charg': 0, 'pleas': 0, 'confirm': 0, 'yup': 0, 'look': 0, 'msg': 0, 'xuhui': 0, 'learn': 0, 'numbrnd': 0, 'lesson': 0, 'numbram': 0, 'oop': 0, 'roommat': 0, 'done': 0, 'see': 0, 'letter': 0, 'decid': 0, 'hello': 0, 'saturday': 0, 'tomo': 0, 'invit': 0, 'pl': 0, 'ahead': 0, 'watt': 0, 'weekend': 0, 'abiola': 0, 'forget': 0, 'need': 0, 'crave': 0, 'sweet': 0, 'arabian': 0, 'steed': 0, 'mmmmmm': 0, 'yummi': 0, 'rodger': 0, 'burn': 0, 'sm': 0, 'nokia': 0, 'camcord': 0, 'deliveri': 0, 'tomorrow': 0, 'hope': 0, 'man': 0, 'well': 0, 'endow': 0, 'lt': 0, 'gt': 0, 'inch': 0, 'hep': 0, 'immunis': 0, 'nigeria': 0, 'fair': 0, 'tyler': 0, 'could': 0, 'mayb': 0, 'ask': 0, 'bit': 0, 'stubborn': 0, 'hospit': 0, 'kept': 0, 'weak': 0, 'sucker': 0, 'saw': 0, 'class': 0, 'gram': 0, 'usual': 0, 'run': 0, 'half': 0, 'eighth': 0, 'smarter': 0, 'almost': 0, 'whole': 0, 'second': 0, 'fyi': 0, 'ride': 0, 'morn': 0, 'crash': 0, 'place': 0, 'wow': 0, 'never': 0, 'realiz': 0, 'embarass': 0, 'accomod': 0, 'thought': 0, 'sinc': 0, 'best': 0, 'seem': 0, 'happi': 0, 'cave': 0, 'sorri': 0, 'give': 0, 'offer': 0, 'ac': 0, 'sptv': 0, 'new': 0, 'jersey': 0, 'devil': 0, 'detroit': 0, 'red': 0, 'wing': 0, 'play': 0, 'ice': 0, 'hockey': 0, 'correct': 0, 'incorrect': 0, 'end': 0, 'mallika': 0, 'sherawat': 0, 'yesterday': 0, 'find': 0, 'url': 0, 'congrat': 0, 'year': 0, 'special': 0, 'cinema': 0, 'pass': 0, 'suprman': 0, 'matrixnumbr': 0, 'starwarsnumbr': 0, 'etc': 0, 'bxnumbr': 0, 'ipnumbr': 0, 'numbrw': 0, 'numbrpm': 0, 'later': 0, 'reach': 0, 'gauti': 0, 'sehwag': 0, 'odi': 0, 'seri': 0, 'pick': 0, 'burger': 0, 'move': 0, 'pain': 0, 'kill': 0, 'good': 0, 'girl': 0, 'situat': 0, 'seeker': 0, 'part': 0, 'check': 0, 'iq': 0, 'took': 0, 'forev': 0, 'come': 0, 'doubl': 0, 'hair': 0, 'dresser': 0, 'said': 0, 'wun': 0, 'cut': 0, 'short': 0, 'nice': 0, 'advis': 0, 'follow': 0, 'recent': 0, 'review': 0, 'mob': 0, 'award': 0, 'bonu': 0, 'song': 0, 'dedic': 0, 'valuabl': 0, 'frnd': 0, 'rpli': 0, 'complimentari': 0, 'trip': 0, 'eurodisinc': 0, 'trav': 0, 'aco': 0, 'entrynumbr': 0, 'di': 0, 'morefrmmob': 0, 'shracomorsglsuplt': 0, 'lsnumbr': 0, 'numbraj': 0, 'hear': 0, 'divorc': 0, 'barbi': 0, 'ken': 0, 'plane': 0, 'wah': 0, 'lucki': 0, 'save': 0, 'money': 0, 'hee': 0, 'hi': 0, 'babe': 0, 'im': 0, 'wan': 0, 'someth': 0, 'xx': 0, 'perform': 0, 'machan': 0, 'that': 0, 'cool': 0, 'gentleman': 0, 'digniti': 0, 'respect': 0, 'peopl': 0, 'much': 0, 'shi': 0, 'pa': 0, 'oper': 0, 'job': 0, 'ta': 0, 'earn': 0, 'ah': 0, 'stop': 0, 'urgnt': 0, 'real': 0, 'yo': 0, 'ticket': 0, 'one': 0, 'jacket': 0, 'multi': 0, 'start': 0, 'came': 0, 'bed': 0, 'coin': 0, 'factori': 0, 'nitro': 0, 'ela': 0, 'kano': 0, 'il': 0, 'download': 0, 'wen': 0, 'stand': 0, 'close': 0, 'anoth': 0, 'night': 0, 'spent': 0, 'late': 0, 'afternoon': 0, 'casualti': 0, 'mean': 0, 'stuffnumbrmoro': 0, 'includ': 0, 'sheet': 0, 'smile': 0, 'pleasur': 0, 'troubl': 0, 'pour': 0, 'rain': 0, 'sumnumbr': 0, 'hurt': 0, 'becoz': 0, 'someon': 0, 'servic': 0, 'repres': 0, 'guarante': 0, 'havent': 0, 'plan': 0, 'buy': 0, 'lido': 0, 'show': 0, 'collect': 0, 'simpli': 0, 'password': 0, 'mix': 0, 'verifi': 0, 'usher': 0, 'britney': 0, 'fml': 0, 'po': 0, 'box': 0, 'mknumbr': 0, 'numbrh': 0, 'numbrppw': 0, 'telugu': 0, 'movi': 0, 'abt': 0, 'load': 0, 'loan': 0, 'wk': 0, 'hol': 0, 'forgot': 0, 'hairdress': 0, 'appoint': 0, 'four': 0, 'shower': 0, 'beforehand': 0, 'caus': 0, 'prob': 0, 'coffe': 0, 'anim': 0, 'noth': 0, 'els': 0, 'okay': 0, 'price': 0, 'long': 0, 'legal': 0, 'ave': 0, 'am': 0, 'gone': 0, 'numbrth': 0, 'drive': 0, 'test': 0, 'yet': 0, 'guess': 0, 'gave': 0, 'boston': 0, 'men': 0, 'chang': 0, 'locat': 0, 'nyc': 0, 'cuz': 0, 'signin': 0, 'page': 0, 'umma': 0, 'life': 0, 'vava': 0, 'lot': 0, 'dear': 0, 'wish': 0, 'birthday': 0, 'truli': 0, 'memor': 0, 'aight': 0, 'hit': 0, 'would': 0, 'ip': 0, 'address': 0, 'consid': 0, 'comput': 0, 'minecraft': 0, 'server': 0, 'grumpi': 0, 'old': 0, 'better': 0, 'lie': 0, 'busi': 0, 'plural': 0, 'noun': 0, 'research': 0, 'thing': 0, 'scare': 0, 'mah': 0, 'loud': 0, 'gent': 0, 'contact': 0, 'last': 0, 'draw': 0, 'knumbr': 0, 'numbrhr': 0, 'numbrppm': 0, 'wa': 0, 'openin': 0, 'sentenc': 0, 'formal': 0, 'anyway': 0, 'juz': 0, 'tt': 0, 'eatin': 0, 'puttin': 0, 'weight': 0, 'haha': 0, 'anythin': 0, 'happen': 0, 'enter': 0, 'cabin': 0, 'boss': 0, 'felt': 0, 'askd': 0, 'apart': 0, 'went': 0, 'holiday': 0, 'flight': 0, 'inc': 0, 'min': 0, 'goodo': 0, 'must': 0, 'friday': 0, 'potato': 0, 'ratio': 0, 'tortilla': 0, 'hmm': 0, 'uncl': 0, 'inform': 0, 'school': 0, 'directli': 0, 'food': 0, 'privat': 0, 'account': 0, 'statement': 0, 'unredeem': 0, 'identifi': 0, 'expir': 0, 'landlin': 0, 'boxnumbrwrnumbrc': 0, 'appl': 0, 'pair': 0, 'malarki': 0, 'voda': 0, 'number': 0, 'match': 0, 'quot': 0, 'standard': 0, 'app': 0, 'sao': 0, 'mu': 0, 'predict': 0, 'yetund': 0, 'sent': 0, 'bother': 0, 'involv': 0, 'impos': 0, 'apologis': 0, 'del': 0, 'bak': 0, 'sum': 0, 'lucyxx': 0, 'tmorrow': 0, 'answer': 0, 'sunshin': 0, 'quiz': 0, 'q': 0, 'top': 0, 'soni': 0, 'dvd': 0, 'player': 0, 'countri': 0, 'algarv': 0, 'ansr': 0, 'sp': 0, 'tyron': 0, 'laid': 0, 'dog': 0, 'direct': 0, 'join': 0, 'largest': 0, 'bt': 0, 'txting': 0, 'gravel': 0, 'nt': 0, 'ecnumbra': 0, 'haf': 0, 'msn': 0, 'yiju': 0, 'hotmail': 0, 'befor': 0, 'activ': 0, 'chat': 0, 'svc': 0, 'hardcor': 0, 'age': 0, 'yr': 0, 'lazi': 0, 'type': 0, 'lect': 0, 'pouch': 0, 'sir': 0, 'mail': 0, 'swt': 0, 'nver': 0, 'tire': 0, 'littl': 0, 'lovabl': 0, 'person': 0, 'coz': 0, 'somtim': 0, 'occupi': 0, 'biggest': 0, 'heart': 0, 'gud': 0, 'ninumbr': 0, 'open': 0, 'ya': 0, 'dot': 0, 'what': 0, 'staff': 0, 'randi': 0, 'sexi': 0, 'femal': 0, 'local': 0, 'luv': 0, 'netcollex': 0, 'ltd': 0, 'ummma': 0, 'begin': 0, 'qatar': 0, 'pray': 0, 'hard': 0, 'delet': 0, 'sindu': 0, 'birla': 0, 'soft': 0, 'wine': 0, 'flow': 0, 'thk': 0, 'plaza': 0, 'typic': 0, 'everywher': 0, 'dirt': 0, 'floor': 0, 'window': 0, 'shirt': 0, 'sometim': 0, 'mouth': 0, 'dream': 0, 'without': 0, 'chore': 0, 'joy': 0, 'tv': 0, 'exist': 0, 'hail': 0, 'mist': 0, 'becom': 0, 'aaooooright': 0, 'leav': 0, 'hous': 0, 'interview': 0, 'boy': 0, 'annonc': 0, 'arrang': 0, 'keep': 0, 'safe': 0, 'envi': 0, 'everyon': 0, 'parent': 0, 'hand': 0, 'excit': 0, 'spend': 0, 'bootydeli': 0, 'f': 0, 'bangbab': 0, 'order': 0, 'content': 0, 'goto': 0, 'bangb': 0, 'internet': 0, 'menu': 0, 'cultur': 0, 'modul': 0, 'snumbr': 0, 'avoid': 0, 'missunderstd': 0, 'wit': 0, 'belov': 0, 'escap': 0, 'fanci': 0, 'bridg': 0, 'lager': 0, 'complet': 0, 'form': 0, 'clark': 0, 'also': 0, 'utter': 0, 'wast': 0, 'axi': 0, 'bank': 0, 'hmmm': 0, 'hop': 0, 'muz': 0, 'discuss': 0, 'liao': 0, 'bloodi': 0, 'hell': 0, 'cant': 0, 'believ': 0, 'surnam': 0, 'mr': 0, 'ill': 0, 'clue': 0, 'spanish': 0, 'bath': 0, 'carlo': 0, 'mall': 0, 'stay': 0, 'til': 0, 'smoke': 0, 'worth': 0, 'doesnt': 0, 'log': 0, 'spoke': 0, 'maneesha': 0, 'satisfi': 0, 'experi': 0, 'toll': 0, 'lift': 0, 'especi': 0, 'approach': 0, 'studi': 0, 'grnumbr': 0, 'trust': 0, 'guy': 0, 'bye': 0, 'handsom': 0, 'toward': 0, 'mummi': 0, 'boytoy': 0, 'awesom': 0, 'minut': 0, 'freephon': 0, 'xma': 0, 'radio': 0, 'ju': 0, 'si': 0, 'uniqu': 0, 'august': 0, 'areyouuniqu': 0, 'leagu': 0, 'touch': 0, 'deal': 0, 'cours': 0, 'howev': 0, 'suggest': 0, 'abl': 0, 'or': 0, 'everi': 0, 'stool': 0, 'settl': 0, 'wishin': 0, 'mrng': 0, 'hav': 0, 'stori': 0, 'hamster': 0, 'dead': 0, 'tmr': 0, 'orchard': 0, 'mrt': 0, 'kate': 0, 'babyjontet': 0, 'found': 0, 'enc': 0, 'buck': 0, 'darlin': 0, 'ive': 0, 'colleg': 0, 'refil': 0, 'success': 0, 'inr': 0, 'decim': 0, 'keralacircl': 0, 'prepaid': 0, 'balanc': 0, 'rs': 0, 'transact': 0, 'id': 0, 'kr': 0, 'goodmorn': 0, 'sleep': 0, 'ga': 0, 'alter': 0, 'dat': 0, 'ericsson': 0, 'oso': 0, 'can': 0, 'not': 0, 'oredi': 0, 'straight': 0, 'dogg': 0, 'connect': 0, 'refund': 0, 'bill': 0, 'shoot': 0, 'big': 0, 'readi': 0, 'bruv': 0, 'break': 0, 'semest': 0, 'noe': 0, 'leh': 0, 'sound': 0, 'head': 0, 'slept': 0, 'past': 0, 'easi': 0, 'sen': 0, 'exam': 0, 'march': 0, 'atm': 0, 'regist': 0, 'os': 0, 'ubandu': 0, 'instal': 0, 'disk': 0, 'import': 0, 'file': 0, 'system': 0, 'repair': 0, 'shop': 0, 'romant': 0, 'nite': 0, 'sceneri': 0, 'tc': 0, 'biz': 0, 'numbroptout': 0, 'numbrgbp': 0, 'mtmsgnumbr': 0, 'appreci': 0, 'partner': 0, 'career': 0, 'flyng': 0, 'horo': 0, 'star': 0, 'sign': 0, 'g': 0, 'ari': 0, 'compani': 0, 'elama': 0, 'mudyadhu': 0, 'strict': 0, 'teacher': 0, 'bcoz': 0, 'teach': 0, 'conduct': 0, 'gandhipuram': 0, 'walk': 0, 'cross': 0, 'road': 0, 'side': 0, 'street': 0, 'rubber': 0, 'batteri': 0, 'die': 0, 'flirt': 0, 'sam': 0, 'recd': 0, 'thirtyeight': 0, 'penc': 0, 'print': 0, 'upstair': 0, 'closer': 0, 'wil': 0, 'theori': 0, 'argument': 0, 'lose': 0, 'argu': 0, 'kick': 0, 'secret': 0, 'admir': 0, 'reveal': 0, 'tomarrow': 0, 'laptop': 0, 'case': 0, 'pleassssssseeeee': 0, 'tel': 0, 'avent': 0, 'sportsx': 0, 'shine': 0, 'meant': 0, 'although': 0, 'told': 0, 'baig': 0, 'face': 0, 'fr': 0, 'thanx': 0, 'everyth': 0, 'commerci': 0, 'websit': 0, 'slipper': 0, 'kalli': 0, 'bat': 0, 'inning': 0, 'didnt': 0, 'goodnight': 0, 'fix': 0, 'wake': 0, 'dearli': 0, 'congratul': 0, 'cd': 0, 'voucher': 0, 'numbrgift': 0, 'music': 0, 'tnc': 0, 'ldew': 0, 'comnumbrwinnumbrppmxnumbragenumbr': 0, 'ranjith': 0, 'cal': 0, 'drpd': 0, 'deeraj': 0, 'deepak': 0, 'numbrmin': 0, 'hold': 0, 'bcum': 0, 'angri': 0, 'wid': 0, 'dnt': 0, 'childish': 0, 'true': 0, 'deep': 0, 'affect': 0, 'care': 0, 'kettoda': 0, 'manda': 0, 'up': 0, 'ship': 0, 'numbrwk': 0, 'usp': 0, 'lag': 0, 'bribe': 0, 'nipost': 0, 'lemm': 0, 'necessarili': 0, 'expect': 0, 'headin': 0, 'mmm': 0, 'jolt': 0, 'suzi': 0, 'lover': 0, 'video': 0, 'handset': 0, 'anytim': 0, 'unlimit': 0, 'park': 0, 'mini': 0, 'disturb': 0, 'luton': 0, 'ring': 0, 'h': 0, 'horni': 0, 'nake': 0, 'hot': 0, 'unsubscrib': 0, 'dint': 0, 'wana': 0, 'sometm': 0, 'clubnumbrmobil': 0, 'choos': 0, 'club': 0, 'clubnumbr': 0, 'boxnumbr': 0, 'numbrwt': 0, 'evo': 0, 'flash': 0, 'jealou': 0, 'singl': 0, 'chart': 0, 'qualiti': 0, 'sort': 0, 'narcot': 0, 'sunni': 0, 'ray': 0, 'blue': 0, 'bay': 0, 'hmv': 0, 'genuin': 0, 'numbrperc': 0, 'might': 0, 'object': 0, 'bf': 0, 'rob': 0, 'mack': 0, 'gf': 0, 'theater': 0, 'celebr': 0, 'full': 0, 'swing': 0, 'tool': 0, 'definit': 0, 'gdeve': 0, 'far': 0, 'oki': 0, 'ahold': 0, 'anybodi': 0, 'throw': 0, 'babi': 0, 'cruisin': 0, 'fone': 0, 'jenni': 0, 'ge': 0, 'shall': 0, 'tonit': 0, 'varunnathu': 0, 'edukkukaye': 0, 'raksha': 0, 'ollu': 0, 'sens': 0, 'gautham': 0, 'stupid': 0, 'cam': 0, 'buzi': 0, 'accident': 0, 'resend': 0, 'phone': 0, 'upgrad': 0, 'sim': 0, 'card': 0, 'loyalti': 0, 'numbrthfeb': 0, 'unless': 0, 'gurl': 0, 'appropri': 0, 'teas': 0, 'plz': 0, 'rose': 0, 'grave': 0, 'bslvyl': 0, 'somebodi': 0, 'high': 0, 'diesel': 0, 'shit': 0, 'shock': 0, 'scari': 0, 'imagin': 0, 'def': 0, 'somewher': 0, 'taxi': 0, 'fridg': 0, 'meal': 0, 'womdarful': 0, 'actor': 0, 'blind': 0, 'numbru': 0, 'roddsnumbr': 0, 'aberdeen': 0, 'unit': 0, 'kingdom': 0, 'img': 0, 'w': 0, 'icmbnumbrcktznumbrrnumbr': 0, 'hide': 0, 'remb': 0, 'book': 0, 'jo': 0, 'friendship': 0, 'hang': 0, 'thread': 0, 'themob': 0, 'newest': 0, 'game': 0, 'tone': 0, 'gossip': 0, 'sport': 0, 'fit': 0, 'funki': 0, 'garag': 0, 'key': 0, 'bookshelf': 0, 'accept': 0, 'sister': 0, 'dearnumbr': 0, 'bestnumbr': 0, 'closnumbr': 0, 'lvblefrnd': 0, 'jstfrnd': 0, 'cutefrnd': 0, 'lifpartnr': 0, 'belovd': 0, 'swtheart': 0, 'bstfrnd': 0, 'enemi': 0, 'smart': 0, 'weekli': 0, 'cs': 0, 'winnersclub': 0, 'mnumbr': 0, 'numbruz': 0, 'gbpnumbr': 0, 'normal': 0, 'rest': 0, 'mylif': 0, 'wot': 0, 'lost': 0, 'made': 0, 'advanc': 0, 'pongal': 0, 'kb': 0, 'power': 0, 'yoga': 0, 'dunno': 0, 'tahan': 0, 'anot': 0, 'lo': 0, 'dude': 0, 'afraid': 0, 'decemb': 0, 'numbrmth': 0, 'cake': 0, 'merri': 0, 'christma': 0, 'kiss': 0, 'cud': 0, 'ppl': 0, 'gona': 0, 'lnumbr': 0, 'buse': 0, 'waitin': 0, 'pete': 0, 'guild': 0, 'bristol': 0, 'problem': 0, 'track': 0, 'record': 0, 'read': 0, 'women': 0, 'light': 0, 'apo': 0, 'return': 0, 'immedi': 0, 'germani': 0, 'line': 0, 'via': 0, 'access': 0, 'prepay': 0, 'evapor': 0, 'violat': 0, 'privaci': 0, 'steal': 0, 'employ': 0, 'paperwork': 0, 'report': 0, 'supervisor': 0, 'valentin': 0, 'lifetim': 0, 'rcvd': 0, 'custcar': 0, 'daaaaa': 0, 'dine': 0, 'surf': 0, 'post': 0, 'wiv': 0, 'carolin': 0, 'favourit': 0, 'stranger': 0, 'interest': 0, 'two': 0, 'round': 0, 'gudnit': 0, 'practic': 0, 'huim': 0, 'num': 0, 'small': 0, 'prestig': 0, 'shag': 0, 'sextextuk': 0, 'xxuk': 0, 'jeremiah': 0, 'iphon': 0, 'apeshit': 0, 'ever': 0, 'misbehav': 0, 'slap': 0, 'urself': 0, 'fault': 0, 'basic': 0, 'figur': 0, 'alcohol': 0, 'jay': 0, 'weed': 0, 'ish': 0, 'ago': 0, 'wtf': 0, 'onam': 0, 'sirji': 0, 'met': 0, 'insur': 0, 'insha': 0, 'allah': 0, 'rakhesh': 0, 'ex': 0, 'tata': 0, 'aig': 0, 'tissco': 0, 'tayseer': 0, 'current': 0, 'maxim': 0, 'cc': 0, 'hg': 0, 'suitenumbr': 0, 'numbrland': 0, 'row': 0, 'wnumbrjnumbrhl': 0, 'unemploy': 0, 'moment': 0, 'st': 0, 'andrew': 0, 'cold': 0, 'chikku': 0, 'db': 0, 'audrey': 0, 'statu': 0, 'forward': 0, 'dawn': 0, 'refresh': 0, 'aliv': 0, 'breath': 0, 'air': 0, 'z': 0, 'update_now': 0, 'motorola': 0, 'sonyericsson': 0, 'bluetooth': 0, 'orang': 0, 'mobileupdnumbr': 0, 'callnumbroptout': 0, 'fnumbrq': 0, 'discount': 0, 'rpnumbr': 0, 'regalportfolio': 0, 'uniform': 0, 'geeee': 0, 'woke': 0, 'cuddl': 0, 'spoil': 0, 'agre': 0, 'will': 0, 'refer': 0, 'tnumbr': 0, 'gbp': 0, 'seen': 0, 'recognis': 0, 'lindsay': 0, 'sigh': 0, 'bar': 0, 'ptbo': 0, 'heron': 0, 'payasam': 0, 'rinu': 0, 'bring': 0, 'taught': 0, 'becau': 0, 'he': 0, 'project': 0, 'prabu': 0, 'mistak': 0, 'bodi': 0, 'quit': 0, 'slow': 0, 'guid': 0, 'ovul': 0, 'relax': 0, 'reason': 0, 'followin': 0, 'coupl': 0, 'wallet': 0, 'numbrmonth': 0, 'nnumbrdx': 0, 'owl': 0, 'lick': 0, 'mm': 0, 'rental': 0, 'mobilesdirect': 0, 'ornumbrstoptxt': 0, 'huh': 0, 'sat': 0, 'intro': 0, 'pilat': 0, 'kickbox': 0, 'offic': 0, 'lap': 0, 'shut': 0, 'bout': 0, 'numbrish': 0, 'calcul': 0, 'period': 0, 'actual': 0, 'rock': 0, 'put': 0, 'pictur': 0, 'ass': 0, 'facebook': 0, 'al': 0, 'salam': 0, 'wahleykkum': 0, 'share': 0, 'grace': 0, 'god': 0, 'inshah': 0, 'visitor': 0, 'india': 0, 'field': 0, 'quickli': 0, 'administr': 0, 'poli': 0, 'numbrx': 0, 'numbrpw': 0, 'nd': 0, 'chechi': 0, 'cream': 0, 'none': 0, 'yep': 0, 'loxahatche': 0, 'tree': 0, 'stoner': 0, 'slightli': 0, 'disastr': 0, 'pm': 0, 'fav': 0, 'wld': 0, 'drink': 0, 'busetop': 0, 'sender': 0, 'fullonsm': 0, 'iron': 0, 'yan': 0, 'jiu': 0, 'skip': 0, 'den': 0, 'blah': 0, 'wendi': 0, 'l': 0, 'boxnumbrsknumbrch': 0, 'whatsup': 0, 'competit': 0, 'txttowin': 0, 'logo': 0, 'namenumbr': 0, 'mobno': 0, 'adam': 0, 'eve': 0, 'yahoo': 0, 'poboxnumbrwnumbrwq': 0, 'txtno': 0, 'ad': 0, 'poboxnumbrnnumbrtfnumbrp': 0, 'siva': 0, 'hostel': 0, 'aha': 0, 'land': 0, 'voic': 0, 'express': 0, 'sentiment': 0, 'rowdi': 0, 'ful': 0, 'attitud': 0}\n"
     ]
    }
   ],
   "source": [
    "# define a find_features functions\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        if word in words:\n",
    "            features[word] = 1\n",
    "        else:\n",
    "            features[word] = 0\n",
    "        \n",
    "    return features\n",
    "\n",
    "# Lets see some results\n",
    "print(processed[4])\n",
    "features = find_features(processed[4])\n",
    "print(features)\n",
    "for key, value in features.items():\n",
    "    if value == {True}:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find features set for all messages\n",
    "messages = zip(processed, Y)\n",
    "\n",
    "# define seed for reproducability\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "#np.random.shuffle(messages)\n",
    "\n",
    "# Call find_features for all SMS messages\n",
    "featuresets = [(find_features(text), label) for (text,label) in messages]\n",
    "\n",
    "#print(featuresets[0])\n",
    "\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#vec = DictVectorizer()\n",
    "#X = vec.fit_transform([item[0] for item in featuresets])\n",
    "#Y = [item[1] for item in featuresets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing datasets using sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform([item[0] for item in ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scikit-Learn Classifier with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model to train\n",
    "names = ['K Nearest Neightbours', 'Decision Tree', 'Random Forest',\n",
    "        'Logistic Regression', 'SGD Classifier', 'Naive Bayes', 'SVM Linear']\n",
    "\n",
    "classifier = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier( max_iter= 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "# Return dictionary\n",
    "models = zip(names, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neightbours: Accuracy: 93.96984924623115\n",
      "Decision Tree: Accuracy: 97.84637473079684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy: 98.49246231155779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy: 98.85139985642498\n",
      "SGD Classifier: Accuracy: 98.42067480258436\n",
      "Naive Bayes: Accuracy: 98.63603732950466\n",
      "SVM Linear: Accuracy: 98.92318736539842\n"
     ]
    }
   ],
   "source": [
    "# Wrap models in nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "for name, model in models:\n",
    "    #print(model)\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing) * 100\n",
    "    print('{}: Accuracy: {}'.format(name,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble method accuracy: 98.85139985642498\n"
     ]
    }
   ],
   "source": [
    "# Build a ensemble method - Voting classifier (Used to combine all classification algorithm used above)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define model to train\n",
    "names = ['K Nearest Neightbours', 'Decision Tree', 'Random Forest',\n",
    "        'Logistic Regression', 'SGD Classifier', 'Naive Bayes', 'SVM Linear']\n",
    "\n",
    "classifier = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier( max_iter= 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "models = list(zip(names, classifier))\n",
    "\n",
    "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
    "nltk_ensemble.train(training)\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, testing) * 100\n",
    "print(\"Ensemble method accuracy: {}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the class label predictions for testing set\n",
    "\n",
    "# Un-zipping file\n",
    "txt_features, labels = zip(*testing)\n",
    "\n",
    "predictions = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1208\n",
      "           1       0.99      0.92      0.96       185\n",
      "\n",
      "    accuracy                           0.99      1393\n",
      "   macro avg       0.99      0.96      0.97      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">actual</td>\n",
       "      <td>ham</td>\n",
       "      <td>1207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spam</td>\n",
       "      <td>15</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                  ham spam\n",
       "actual ham       1207    1\n",
       "       spam        15  170"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix and a classification report\n",
    "print(classification_report(labels, predictions))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels,predictions),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
